{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Lab Assignment 2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GlGRWcpuDVt"
      },
      "source": [
        "## NLP Lab Assignment 2\n",
        "\n",
        "***Student Details:***\n",
        "\n",
        "- Name : Anjishnu Mukherjee\n",
        "- Registration Number : B05-511017020\n",
        "- Exam Roll Number : 510517086\n",
        "- Email : 511017020.anjishnu@students.iiests.ac.in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJUxdRxG1hBd"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuRiUQtus5a4",
        "outputId": "c97f99f5-86a0-472d-b39d-32806ac0e2cd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZXm2tt_vAH5"
      },
      "source": [
        "## Data files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aydAFAV-s6uA"
      },
      "source": [
        "data_dir = \"/content/drive/MyDrive/NLP_LAB/Assignment-2/\"\n",
        "data_file_1 = \"big.txt\"\n",
        "data_file_2 = \"shakespeare.txt\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjMRWFabu_YW"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tckAnsLr-e_"
      },
      "source": [
        "import functools\n",
        "import math\n",
        "from typing import Dict, List, Optional, Any\n",
        "\n",
        "import re\n",
        "from collections import Counter"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39qIWPDgvEHN"
      },
      "source": [
        "## Minimum Edit Distance Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xwkmasTsOB6"
      },
      "source": [
        "# utility function\n",
        "def ignore_unhashable(func):\n",
        "    \"\"\"[To allow caching the distance matrix in its original form, which is a\n",
        "        list of lists. Reference : ->\n",
        "        https://stackoverflow.com/a/64111268/11009359]\n",
        "\n",
        "    Args:\n",
        "        func ([type]): [The function where we intend to apply this decorator.]\n",
        "    \"\"\"\n",
        "    uncached = func.__wrapped__\n",
        "    attributes = functools.WRAPPER_ASSIGNMENTS + (\"cache_info\", \"cache_clear\")\n",
        "\n",
        "    @functools.wraps(func, assigned=attributes)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        try:\n",
        "            return func(*args, **kwargs)\n",
        "        except TypeError as error:\n",
        "            if \"unhashable type\" in str(error):\n",
        "                return uncached(*args, **kwargs)\n",
        "            raise\n",
        "\n",
        "    wrapper.__uncached__ = uncached\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "class MinimumEditDistance:\n",
        "    def __init__(\n",
        "        self,\n",
        "        insertion_cost: Optional[int] = 1,\n",
        "        deletion_cost: Optional[int] = 1,\n",
        "        substitution_cost: Optional[int] = 2,\n",
        "    ) -> None:\n",
        "        \"\"\"[Creates an instance for the class.]\n",
        "\n",
        "        Args:\n",
        "            insertion_cost (Optional[int], optional): [description]. Defaults to 1.\n",
        "            deletion_cost (Optional[int], optional): [description]. Defaults to 1.\n",
        "            substitution_cost (Optional[int], optional): [description]. Defaults to 2.\n",
        "        \"\"\"\n",
        "        self.__insertion_cost = insertion_cost\n",
        "        self.__deletion_cost = deletion_cost\n",
        "        self.__substitution_cost = substitution_cost\n",
        "\n",
        "    def align(self, query: str, target: str) -> Dict:\n",
        "        \"\"\"[Compute edit distance. Return a dictionary containing the edit\n",
        "            distance, the matrix from Wagner Fischer algorithm, a single optimal\n",
        "            alignment, and a list of all possible alignments.]\n",
        "\n",
        "        Args:\n",
        "            query (str): [The query string.]\n",
        "            target (str): [The target string.]\n",
        "\n",
        "        Returns:\n",
        "            Dict: [Wagner Fischer results, single optimal alignment, all optimal\n",
        "            alignments]\n",
        "        \"\"\"\n",
        "        wagner_fischer_results = self.weightedWagnerFischer(query, target)\n",
        "\n",
        "        single_optimal_alignment = self.getOptimalAlignment(\n",
        "            query, target, wagner_fischer_results[\"distance_matrix\"]\n",
        "        )\n",
        "\n",
        "        all_optimal_alignments = self.getAllOptimalAlignments(\n",
        "            query, target, wagner_fischer_results[\"distance_matrix\"]\n",
        "        )\n",
        "\n",
        "        result = dict()\n",
        "        result[\"wagner_fischer_results\"] = wagner_fischer_results\n",
        "        result[\"single_optimal_alignment\"] = single_optimal_alignment\n",
        "        result[\"all_optimal_alignments\"] = all_optimal_alignments\n",
        "        return result\n",
        "\n",
        "    def niceMatrix(self, matrix: List) -> None:\n",
        "        \"\"\"[Prints a matrix in a nice human readable format.]\n",
        "\n",
        "        Args:\n",
        "            matrix (List): [The matrix which will be printed, stored as a list\n",
        "            of lists.]\n",
        "        \"\"\"\n",
        "        print(\n",
        "            \"\\n\".join(\n",
        "                [\n",
        "                    \"\".join([\"{:4}\".format(item) for item in row])\n",
        "                    for row in matrix\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def niceAlignment(self, alignment: Dict) -> None:\n",
        "        \"\"\"[Prints the alignment of query and target in a nice human readable\n",
        "        format.]\n",
        "\n",
        "        Args:\n",
        "            alignment (Dict): [A dictionary containing the aligned query and\n",
        "            target strings, and a string for the actions needed for alignment.\n",
        "            For the string of operations, d is for delete, i is for insertion, |\n",
        "            is for match, s is for substitution. For the aligned target and\n",
        "            query strings, - corresponds to an insertion or deletion.]\n",
        "        \"\"\"\n",
        "        query, target, operations = (\n",
        "            alignment[\"aligned_query\"],\n",
        "            alignment[\"aligned_target\"],\n",
        "            alignment[\"operations\"],\n",
        "        )\n",
        "        print(\n",
        "            \" \".join(query)\n",
        "            + \"\\n\"\n",
        "            + \" \".join(operations)\n",
        "            + \"\\n\"\n",
        "            + \" \".join(target)\n",
        "        )\n",
        "\n",
        "    def weightedWagnerFischer(self, query: str, target: str) -> Dict:\n",
        "        \"\"\"[Implements the Wagner Fischer algorithm. Details of the algorithm\n",
        "        can be found here ->\n",
        "        https://en.wikipedia.org/wiki/Wagnerâ€“Fischer_algorithm .]\n",
        "\n",
        "            Args:\n",
        "                query (str): [The query string.]\n",
        "                target (str): [The target string.]\n",
        "\n",
        "            Returns:\n",
        "                Dict: [Contains the edit distance between query and target\n",
        "                strings and also the distance matrix.]\n",
        "        \"\"\"\n",
        "        len1, len2 = len(query), len(target)\n",
        "        distance = [[0 for i in range(len2 + 1)] for j in range(len1 + 1)]\n",
        "\n",
        "        # query prefixes can be transformed into empty target by deleting all\n",
        "        # characters\n",
        "        for i in range(len1 + 1):\n",
        "            distance[i][0] = i * self.__deletion_cost\n",
        "\n",
        "        # target prefixes can be reached from empty query prefix by inserting\n",
        "        # every character\n",
        "        for i in range(len2 + 1):\n",
        "            distance[0][i] = i * self.__insertion_cost\n",
        "\n",
        "        for i in range(1, len1 + 1):\n",
        "            for j in range(1, len2 + 1):\n",
        "                diagonal = distance[i - 1][j - 1] + (\n",
        "                    0\n",
        "                    if query[i - 1] == target[j - 1]\n",
        "                    else self.__substitution_cost\n",
        "                )\n",
        "                left = distance[i][j - 1] + self.__insertion_cost\n",
        "                up = distance[i - 1][j] + self.__deletion_cost\n",
        "\n",
        "                distance[i][j] = min(diagonal, left, up)\n",
        "\n",
        "        edit_distance = distance[len1][len2]\n",
        "        wagner_fischer_results = dict()\n",
        "        wagner_fischer_results[\"edit_distance\"] = edit_distance\n",
        "        wagner_fischer_results[\"distance_matrix\"] = distance\n",
        "        return wagner_fischer_results\n",
        "\n",
        "    @staticmethod\n",
        "    def reverseString(input_string: str) -> str:\n",
        "        \"\"\"[Utility method to reverse a string.]\n",
        "\n",
        "        Args:\n",
        "            input_string (str): [The string to be reversed.]\n",
        "\n",
        "        Returns:\n",
        "            str: [The reversed string.]\n",
        "        \"\"\"\n",
        "        start = stop = None\n",
        "        step = -1\n",
        "        reverse_slice = slice(start, stop, step)\n",
        "        return input_string[reverse_slice]\n",
        "\n",
        "    def getOptimalAlignment(\n",
        "        self, query: str, target: str, distance: List\n",
        "    ) -> Dict:\n",
        "        \"\"\"[Get a single optimal alignment from the edit distance matrix.]\n",
        "\n",
        "        Args:\n",
        "            query (str): [The query string.]\n",
        "            target (str): [The target string.]\n",
        "            distance (List): [The edit distance matrix from Wagner Fischer\n",
        "            algorithm.]\n",
        "\n",
        "        Returns:\n",
        "            Dict: [A dictionary containing the aligned query and target strings\n",
        "            and a string of the operations needed for tha alignment.]\n",
        "        \"\"\"\n",
        "        aligned_query, aligned_target, operation = \"\", \"\", \"\"\n",
        "        i, j = len(query), len(target)\n",
        "\n",
        "        while i != 0 or j != 0:\n",
        "\n",
        "            # find the value of diagonal, top and left cells if they exist\n",
        "            is_match = False\n",
        "            diagonal, top, left = math.inf, math.inf, math.inf\n",
        "            if i != 0 and j != 0:\n",
        "                is_match = query[i - 1] == target[j - 1]\n",
        "                diagonal = distance[i - 1][j - 1] + (\n",
        "                    0 if is_match else self.__substitution_cost\n",
        "                )\n",
        "            if i != 0:\n",
        "                top = distance[i - 1][j] + self.__deletion_cost\n",
        "            if j != 0:\n",
        "                left = distance[i][j - 1] + self.__insertion_cost\n",
        "\n",
        "            # find global min of the three cells\n",
        "            min_dist = min(diagonal, top, left)\n",
        "\n",
        "            # check which of those 3 cells correspond to the global min\n",
        "            if diagonal == min_dist:\n",
        "                aligned_query += query[i - 1]\n",
        "                aligned_target += target[j - 1]\n",
        "                operation += \"|\" if is_match else \"s\"\n",
        "                i -= 1\n",
        "                j -= 1\n",
        "            elif top == min_dist:\n",
        "                aligned_query += query[i - 1]\n",
        "                aligned_target += \"-\"\n",
        "                operation += \"d\"\n",
        "                i -= 1\n",
        "            else:\n",
        "                aligned_query += \"-\"\n",
        "                aligned_target += target[j - 1]\n",
        "                operation += \"i\"\n",
        "                j -= 1\n",
        "\n",
        "        aligned_query, aligned_target, operation = (\n",
        "            self.reverseString(aligned_query),\n",
        "            self.reverseString(aligned_target),\n",
        "            self.reverseString(operation),\n",
        "        )\n",
        "\n",
        "        optimal_alignment = dict()\n",
        "        optimal_alignment[\"aligned_query\"] = aligned_query\n",
        "        optimal_alignment[\"aligned_target\"] = aligned_target\n",
        "        optimal_alignment[\"operations\"] = operation\n",
        "        return optimal_alignment\n",
        "\n",
        "    def getAllOptimalAlignments(\n",
        "        self, query: str, target: str, distance: List\n",
        "    ) -> List:\n",
        "        \"\"\"[Wrapper method that calls a private method which performs\n",
        "        backtracking to return all optimal alignments. ]\n",
        "\n",
        "        Args:\n",
        "            query (str): [The query string.]\n",
        "            target (str): [The target string.]\n",
        "            distance (List): [The edit distance matrix from Wagner Fischer.]\n",
        "\n",
        "        Returns:\n",
        "            List: [A list of dictionaries, where each dictionary is an\n",
        "            alignment.]\n",
        "        \"\"\"\n",
        "        self.__alignments = []\n",
        "        self.__get_all_optimal_alignments(\n",
        "            query, target, distance, len(query), len(target), \"\", \"\", \"\"\n",
        "        )\n",
        "        return self.__alignments\n",
        "\n",
        "    @ignore_unhashable\n",
        "    @functools.lru_cache(maxsize=10)\n",
        "    def __get_all_optimal_alignments(\n",
        "        self,\n",
        "        query: str,\n",
        "        target: str,\n",
        "        distance: List,\n",
        "        i: int,\n",
        "        j: int,\n",
        "        aligned_query: str,\n",
        "        aligned_target: str,\n",
        "        operation: str,\n",
        "    ) -> None:\n",
        "        \"\"\"[A backtracking algorithm that finds all paths from distance[m][n] to\n",
        "        distance[0][0], where distance is the edit distance matrix from weighed\n",
        "        Wagner Fischer algorithm, and m and n are the lengths of the query and\n",
        "        target strings respectively. The paths found are the represented as\n",
        "        alignments which are then stored in a private class member list. Up to\n",
        "        10 most recent calls are cached in a lru cache.]\n",
        "\n",
        "        Args:\n",
        "            query (str): [The query string.]\n",
        "            target (str): [The target string.]\n",
        "            distance (List): [The edit distance matrix from weighted Wagner\n",
        "            Fischer algorithm.]\n",
        "            i (int): [The starting index for this recursive backtracking\n",
        "            algorithm, for query string.]\n",
        "            j (int): [The starting index for this recursive backtracking\n",
        "            algorithm, for target string.]\n",
        "            aligned_query (str): [Aligned query string.]\n",
        "            aligned_target (str): [Aligned target string.]\n",
        "            operation (str): [String of operations for converting query to\n",
        "            target.]\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        if i == 0 and j == 0:\n",
        "            optimal_alignment = dict()\n",
        "            optimal_alignment[\"aligned_query\"] = self.reverseString(\n",
        "                aligned_query\n",
        "            )\n",
        "            optimal_alignment[\"aligned_target\"] = self.reverseString(\n",
        "                aligned_target\n",
        "            )\n",
        "            optimal_alignment[\"operations\"] = self.reverseString(operation)\n",
        "            self.__alignments.append(optimal_alignment)\n",
        "\n",
        "        else:\n",
        "\n",
        "            # find the value of diagonal, top and left cells if they exist\n",
        "            is_match = False\n",
        "            diagonal, top, left = math.inf, math.inf, math.inf\n",
        "            if i != 0 and j != 0:\n",
        "                is_match = query[i - 1] == target[j - 1]\n",
        "                diagonal = distance[i - 1][j - 1] + (\n",
        "                    0 if is_match else self.__substitution_cost\n",
        "                )\n",
        "            if i != 0:\n",
        "                top = distance[i - 1][j] + self.__deletion_cost\n",
        "            if j != 0:\n",
        "                left = distance[i][j - 1] + self.__insertion_cost\n",
        "\n",
        "            # find global min of the three cells\n",
        "            min_dist = min(diagonal, top, left)\n",
        "\n",
        "            # check which of those 3 cells correspond to the global min\n",
        "            if diagonal == min_dist:\n",
        "                self.__get_all_optimal_alignments(\n",
        "                    query,\n",
        "                    target,\n",
        "                    distance,\n",
        "                    i - 1,\n",
        "                    j - 1,\n",
        "                    aligned_query + query[i - 1],\n",
        "                    aligned_target + target[j - 1],\n",
        "                    operation + (\"|\" if is_match else \"s\"),\n",
        "                )\n",
        "            if top == min_dist:\n",
        "                self.__get_all_optimal_alignments(\n",
        "                    query,\n",
        "                    target,\n",
        "                    distance,\n",
        "                    i - 1,\n",
        "                    j,\n",
        "                    aligned_query + query[i - 1],\n",
        "                    aligned_target + \"-\",\n",
        "                    operation + \"d\",\n",
        "                )\n",
        "            if left == min_dist:\n",
        "                self.__get_all_optimal_alignments(\n",
        "                    query,\n",
        "                    target,\n",
        "                    distance,\n",
        "                    i,\n",
        "                    j - 1,\n",
        "                    aligned_query + \"-\",\n",
        "                    aligned_target + target[j - 1],\n",
        "                    operation + \"i\",\n",
        "                )\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq05DGp6vIb7"
      },
      "source": [
        "## Minimum Edit Distance Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UySCX9qTsOD3"
      },
      "source": [
        "str1 = \"TELEPHONE\"\n",
        "str2 = \"ELEPHANT\"\n",
        "\n",
        "med = MinimumEditDistance(1, 1, 2)\n",
        "alignment = med.align(str1, str2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4h3r1_gvMlS"
      },
      "source": [
        "### Edit Distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDDBFVdKsWTa",
        "outputId": "ceb9a442-1ce6-4617-bfce-5705579822c4"
      },
      "source": [
        "print(\n",
        "    \"Edit Distance : \",\n",
        "    alignment[\"wagner_fischer_results\"][\"edit_distance\"],\n",
        ")\n",
        "print()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Edit Distance :  5\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUdCdxumvO2q"
      },
      "source": [
        "### Distance Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VC60Y5GsUOe",
        "outputId": "201ade49-c9d7-401a-b3c3-2151c2355bd7"
      },
      "source": [
        "print(\"Edit Distance Matrix :\")\n",
        "med.niceMatrix(\n",
        "    alignment[\"wagner_fischer_results\"][\"distance_matrix\"]\n",
        ")\n",
        "print()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Edit Distance Matrix :\n",
            "   0   1   2   3   4   5   6   7   8\n",
            "   1   2   3   4   5   6   7   8   7\n",
            "   2   1   2   3   4   5   6   7   8\n",
            "   3   2   1   2   3   4   5   6   7\n",
            "   4   3   2   1   2   3   4   5   6\n",
            "   5   4   3   2   1   2   3   4   5\n",
            "   6   5   4   3   2   1   2   3   4\n",
            "   7   6   5   4   3   2   3   4   5\n",
            "   8   7   6   5   4   3   4   3   4\n",
            "   9   8   7   6   5   4   5   4   5\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAl8FiiBvROI"
      },
      "source": [
        "### Single Optimal Alignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWHyk3uMsX5w",
        "outputId": "9061c6df-4fa9-4331-869a-5bda4fceebad"
      },
      "source": [
        "print(\"Single Optimal Alignment : \")\n",
        "med.niceAlignment(alignment[\"single_optimal_alignment\"])\n",
        "print()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Single Optimal Alignment : \n",
            "T E L E P H O N E\n",
            "d | | | | | s | s\n",
            "- E L E P H A N T\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Osfkr4-JvUOn"
      },
      "source": [
        "### All Optimal Alignments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TST_4OqzsZWz",
        "outputId": "67deecd7-e59b-447d-d7b2-03a9bd3fcafe"
      },
      "source": [
        "print(\"All Optimal Alignments : \")\n",
        "for i in range(len(alignment[\"all_optimal_alignments\"])):\n",
        "    optimal_alignment = alignment[\"all_optimal_alignments\"][i]\n",
        "    print(\"-\"*30)\n",
        "    print(\"Alignment #\",i + 1)\n",
        "    print(\"-\"*30)\n",
        "    med.niceAlignment(optimal_alignment)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All Optimal Alignments : \n",
            "------------------------------\n",
            "Alignment # 1\n",
            "------------------------------\n",
            "T E L E P H O N E\n",
            "d | | | | | s | s\n",
            "- E L E P H A N T\n",
            "------------------------------\n",
            "Alignment # 2\n",
            "------------------------------\n",
            "T E L E P H - O N E\n",
            "d | | | | | i d | s\n",
            "- E L E P H A - N T\n",
            "------------------------------\n",
            "Alignment # 3\n",
            "------------------------------\n",
            "T E L E P H O - N E\n",
            "d | | | | | d i | s\n",
            "- E L E P H - A N T\n",
            "------------------------------\n",
            "Alignment # 4\n",
            "------------------------------\n",
            "T E L E P H O N - E\n",
            "d | | | | | s | i d\n",
            "- E L E P H A N T -\n",
            "------------------------------\n",
            "Alignment # 5\n",
            "------------------------------\n",
            "T E L E P H - O N - E\n",
            "d | | | | | i d | i d\n",
            "- E L E P H A - N T -\n",
            "------------------------------\n",
            "Alignment # 6\n",
            "------------------------------\n",
            "T E L E P H O - N - E\n",
            "d | | | | | d i | i d\n",
            "- E L E P H - A N T -\n",
            "------------------------------\n",
            "Alignment # 7\n",
            "------------------------------\n",
            "T E L E P H O N E -\n",
            "d | | | | | s | d i\n",
            "- E L E P H A N - T\n",
            "------------------------------\n",
            "Alignment # 8\n",
            "------------------------------\n",
            "T E L E P H - O N E -\n",
            "d | | | | | i d | d i\n",
            "- E L E P H A - N - T\n",
            "------------------------------\n",
            "Alignment # 9\n",
            "------------------------------\n",
            "T E L E P H O - N E -\n",
            "d | | | | | d i | d i\n",
            "- E L E P H - A N - T\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQIPGjeCvXZE"
      },
      "source": [
        "## AutoCorrect class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAM911vlsjzd"
      },
      "source": [
        "class AutoCorrect:\n",
        "    def __init__(self, word_corpus: str) -> None:\n",
        "        \"\"\"Creates an instance for the class.\"\"\"\n",
        "        try:\n",
        "            with open(word_corpus, \"r\") as inputFile:\n",
        "                self.__word_corpus = inputFile.read()\n",
        "                self.load_corpus()\n",
        "        except IOError:\n",
        "            print(\"Couldn't read input corpus.\")\n",
        "            exit(1)\n",
        "\n",
        "    @staticmethod\n",
        "    def tokenize(text: str) -> List:\n",
        "        \"\"\"List all the word tokens (consecutive letters) in a text.\n",
        "        Normalize to lowercase.\"\"\"\n",
        "        return re.findall(\"[a-z]+\", text.lower())\n",
        "\n",
        "    @functools.lru_cache(maxsize=100)\n",
        "    def load_corpus(self) -> None:\n",
        "        \"\"\"Tokenize the corpus and load it into a Counter.\"\"\"\n",
        "        self.CORPUS = self.tokenize(self.__word_corpus)\n",
        "        self.COUNTS = Counter(self.CORPUS)\n",
        "        self.UNIQUE_WORDS = sorted(set(self.CORPUS))\n",
        "\n",
        "    def print_info(\n",
        "        self, candidates: List, edit_distances: List, probabilites: List\n",
        "    ) -> None:\n",
        "        \"\"\"Helper function for printing viable candidates, their frequencies and\n",
        "        edit_distances when use_frequency=True.\n",
        "        \"\"\"\n",
        "        print(\n",
        "            \"\\nUsing a dictionary of \",\n",
        "            len(self.UNIQUE_WORDS),\n",
        "            \" unique words \\nand a total of \",\n",
        "            len(self.CORPUS),\n",
        "            \" words to predict the most probable word...\\n\",\n",
        "        )\n",
        "\n",
        "        l = list(zip(candidates, probabilites, edit_distances))\n",
        "\n",
        "        # sort by frequency\n",
        "        l = sorted(l, key=lambda t: t[1], reverse=True)\n",
        "\n",
        "        # sort by edit distance\n",
        "        l = sorted(l, key=lambda t: t[2])\n",
        "\n",
        "        print(\"List of viable candidates :\")\n",
        "        print(\"-\" * 80)\n",
        "        print(\n",
        "            \"{:>20}{:>20}{:>20}\".format(\n",
        "                \"candidate\", \"frequency\", \"edit_distance\"\n",
        "            )\n",
        "        )\n",
        "        print(\"-\" * 80)\n",
        "        for c, p, d in l:\n",
        "            print(\"{:>20}{:>20}{:>20}\".format(c, p, d))\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "    def autocorrect(\n",
        "        self,\n",
        "        word: str,\n",
        "        threshold: Optional[int] = 2,\n",
        "        use_frequency: Optional[bool] = True,\n",
        "    ) -> Any:\n",
        "        \"\"\"\n",
        "        Given a word w, find the most likely correction c = correct(w).\n",
        "\n",
        "        Approach: Try all candidate words c that are known words that are 'near'\n",
        "        w. Choose the most 'likely' one.\n",
        "\n",
        "        To balance near and likely, in a trivial way: Measure nearness by\n",
        "        edit distance <= threshold, and choose the most likely word from the\n",
        "        given text by frequency.\n",
        "\n",
        "        Reference :\n",
        "        http://nbviewer.jupyter.org/url/norvig.com/ipython/How%20to%20Do%20Things%20with%20Words.ipynb\n",
        "        \"\"\"\n",
        "        word = word.lower()\n",
        "\n",
        "        # if the word is in the loaded corpus,\n",
        "        if word in self.UNIQUE_WORDS:\n",
        "            print(\"No corrections required.\")\n",
        "            return word\n",
        "\n",
        "        med = MinimumEditDistance(\n",
        "            insertion_cost=1, deletion_cost=1, substitution_cost=2\n",
        "        )\n",
        "\n",
        "        candidates = []\n",
        "        edit_distances = []\n",
        "        for candidate in self.UNIQUE_WORDS:\n",
        "            weightedWagnerFischerResults = med.weightedWagnerFischer(\n",
        "                word, candidate\n",
        "            )\n",
        "            distance = weightedWagnerFischerResults[\"edit_distance\"]\n",
        "            if distance <= threshold:\n",
        "                candidates.append(candidate)\n",
        "                edit_distances.append(distance)\n",
        "\n",
        "        if not candidates:\n",
        "            print(\"No viable correction found for given word.\")\n",
        "            return word\n",
        "\n",
        "        if not use_frequency:\n",
        "            return candidates\n",
        "\n",
        "        else:\n",
        "            probabilites = []\n",
        "            for possible in candidates:\n",
        "                probabilites.append(self.COUNTS[possible])\n",
        "            l = list(zip(candidates, probabilites, edit_distances))\n",
        "\n",
        "            # prefer edits that are 1 edit away\n",
        "            edit1 = [c for c, p, d in l if d == 1]\n",
        "            if edit1:\n",
        "                viable_candidate = max(edit1, key=self.COUNTS.get)\n",
        "\n",
        "            # if there are no words 1 edit away, consider all words\n",
        "            else:\n",
        "                viable_candidate = max(candidates, key=self.COUNTS.get)\n",
        "\n",
        "            return viable_candidate, candidates, edit_distances, probabilites\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOQ_WWbmvZyq"
      },
      "source": [
        "## AutoCorrect example, using input dictionary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0znCqAT3srDD"
      },
      "source": [
        "autocorrection_tool = AutoCorrect(data_dir+data_file_2)\n",
        "test1 = \"sui\"\n",
        "(\n",
        "    x1,\n",
        "    candidates,\n",
        "    edit_distances,\n",
        "    probabilites,\n",
        ") = autocorrection_tool.autocorrect(test1, threshold=2, use_frequency=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Yw5wxz4stfH",
        "outputId": "abe62b23-0450-4702-e58b-bc7f24b28e70"
      },
      "source": [
        "autocorrection_tool.print_info(\n",
        "    candidates, edit_distances, probabilites\n",
        ")\n",
        "print(\"Given word : \", test1)\n",
        "print(\"Chosen candidate(s) : \", x1)\n",
        "print()\n",
        "print()\n",
        "print(\"-\" * 80)\n",
        "print()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using a dictionary of  23683  unique words \n",
            "and a total of  928012  words to predict the most probable word...\n",
            "\n",
            "List of viable candidates :\n",
            "--------------------------------------------------------------------------------\n",
            "           candidate           frequency       edit_distance\n",
            "--------------------------------------------------------------------------------\n",
            "                suit                 145                   1\n",
            "                suis                   4                   1\n",
            "                  si                   3                   1\n",
            "                  su                   2                   1\n",
            "                   i               22538                   2\n",
            "                   s                7723                   2\n",
            "                 sir                2764                   2\n",
            "                 sun                 237                   2\n",
            "                 sit                 214                   2\n",
            "                 sin                 159                   2\n",
            "                 six                  62                   2\n",
            "                 sum                  56                   2\n",
            "               suits                  32                   2\n",
            "                 sue                  27                   2\n",
            "                 sup                  20                   2\n",
            "                 oui                   6                   2\n",
            "                 qui                   6                   2\n",
            "                 sug                   4                   2\n",
            "                 sur                   4                   2\n",
            "                 sip                   3                   2\n",
            "                 siz                   3                   2\n",
            "                   u                   3                   2\n",
            "               sluic                   2                   2\n",
            "                 sub                   1                   2\n",
            "--------------------------------------------------------------------------------\n",
            "Given word :  sui\n",
            "Chosen candidate(s) :  suit\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MawYpmXrveI3"
      },
      "source": [
        "## AutoCorrect example, without dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdR157aQtf4d",
        "outputId": "8b7045ce-4591-4d73-a9be-a692d137b899"
      },
      "source": [
        "autocorrection_tool = AutoCorrect(data_dir+data_file_2)\n",
        "test2 = \"sui\"\n",
        "x2 = autocorrection_tool.autocorrect(test2, threshold=2, use_frequency=False)\n",
        "print(\"Given word : \", test2)\n",
        "print(\"Chosen candidate(s) : \", x2)\n",
        "print()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Given word :  sui\n",
            "Chosen candidate(s) :  ['i', 'oui', 'qui', 's', 'si', 'sin', 'sip', 'sir', 'sit', 'six', 'siz', 'sluic', 'su', 'sub', 'sue', 'sug', 'suis', 'suit', 'suits', 'sum', 'sun', 'sup', 'sur', 'u']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}