{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Lab Assignment 1",
      "provenance": [],
      "collapsed_sections": [
        "Wwo1PN7F1oCj",
        "nNyKutLr1dis",
        "UPDjDRjJ04G_",
        "1HQCbyzm06J2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GlGRWcpuDVt"
      },
      "source": [
        "## NLP Lab Assignment 1\n",
        "\n",
        "***Student Details:***\n",
        "\n",
        "- Name : Anjishnu Mukherjee\n",
        "- Registration Number : B05-511017020\n",
        "- Exam Roll Number : 510517086\n",
        "- Email : 511017020.anjishnu@students.iiests.ac.in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJUxdRxG1hBd"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P36wvOdZ0HCD",
        "outputId": "ebeb0eca-6c63-465b-b55e-e94812f559d6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-C6QAXD1kYi"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OzS0GrV0O81"
      },
      "source": [
        "import random\n",
        "import string\n",
        "from typing import List, Optional\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import brown, stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQLRSXGS0Qec",
        "outputId": "4f0bb30f-7092-4229-c075-b523c73e22df"
      },
      "source": [
        "nltk.download(\"brown\")\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wwo1PN7F1oCj"
      },
      "source": [
        "## Data files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnVJzcO10Swr"
      },
      "source": [
        "data_dir = \"/content/drive/MyDrive/NLP_LAB/Assignment-1/\"\n",
        "data_file_1 = \"sample-text-1.txt\"\n",
        "data_file_2 = \"sample-text-2.txt\"\n",
        "bengali_stopwords = \"stopwords-bn.txt\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNyKutLr1dis"
      },
      "source": [
        "## Solution class\n",
        "\n",
        "- Here, I define a class which takes the language, stopwords and the input text file as parameters. \n",
        "- All the required functionality of the assignment are defined as methods of this class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djqPSftfkGO4"
      },
      "source": [
        "class Basics:\n",
        "    ''' Assignment 1 Solution Class'''\n",
        "\n",
        "    def __init__(self, path: str, language: str,\n",
        "                 stop_words: Optional[str] = None) -> None:\n",
        "        '''Creates an object of the class with given parameters.'''\n",
        "\n",
        "        super().__init__()\n",
        "        self.PATH = path\n",
        "        self.language = language\n",
        "        self.stop_words = stop_words\n",
        "\n",
        "        try:\n",
        "            with open(self.PATH, 'r') as inputFile:\n",
        "                self.raw_text = inputFile.read()\n",
        "        except IOError:\n",
        "            self.raw_text = None\n",
        "            print(\"Couldn't read input file.\")\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        '''Formalized string representation of this class.'''\n",
        "\n",
        "        rep = self.__class__.__qualname__ + \\\n",
        "            '(' + self.PATH + ',' + self.language + ') object.'\n",
        "        return rep\n",
        "\n",
        "    def add_line_numbers(self) -> None:\n",
        "        '''Add a line number to every non-empty line of input file and print it.'''\n",
        "\n",
        "        if self.raw_text is not None:\n",
        "            line_number = 1\n",
        "            for line in self.raw_text.splitlines():\n",
        "\n",
        "                # empty lines and whitespaces are ignored\n",
        "                if not line.isspace() and line != \"\":\n",
        "                    print(line_number, \"\\t\", line)\n",
        "                    line_number += 1\n",
        "        else:\n",
        "            raise Exception(\"Couldn't read input file.\")\n",
        "\n",
        "    def __tokenize(self, text: Optional[str] = None) -> List:\n",
        "        '''Normalizes input text by converting to lower case and then tokenizing\n",
        "        it.'''\n",
        "\n",
        "        if not text:\n",
        "            if self.raw_text is not None:\n",
        "                return word_tokenize(self.raw_text.lower())\n",
        "            else:\n",
        "                raise Exception(\"Couldn't read input file.\")\n",
        "        else:\n",
        "            if text:\n",
        "                return word_tokenize(text.lower())\n",
        "            else:\n",
        "                raise Exception(\"Can't tokenize input string.\")\n",
        "\n",
        "    def __remove_punctuations(self, tokens: List) -> List:\n",
        "        '''Removes all possible punctuations from the list of tokens.'''\n",
        "\n",
        "        if tokens:\n",
        "            # list of all English punctuations\n",
        "            punctuations = set(string.punctuation)\n",
        "\n",
        "            # this is the only Bengali punctuation which is not there in English\n",
        "            if self.language == 'bn':\n",
        "                punctuations.add('।')\n",
        "\n",
        "            # if at least one of the characters is not a punctuation, it is a word.\n",
        "            # this removes all the single character punctuations from the list of\n",
        "            # tokens.\n",
        "            words = []\n",
        "            for token in tokens:\n",
        "                for char in token:\n",
        "                    if char not in punctuations:\n",
        "                        words.append(token)\n",
        "                        break\n",
        "\n",
        "            return words\n",
        "        else:\n",
        "            raise Exception(\"No tokens found.\")\n",
        "\n",
        "    def __clean_tokens(self, tokens: List) -> List:\n",
        "        '''Removes stopwords, contractions, conjunctions.'''\n",
        "\n",
        "        if tokens:\n",
        "            # use english stopwords by default, otherwise use specified stopwords\n",
        "            if self.stop_words == None:\n",
        "                stop_words = set(stopwords.words('english'))\n",
        "            else:\n",
        "                stop_words = self.stop_words\n",
        "\n",
        "            # remove stopwords from collection of tokens\n",
        "            clean_tokens = []\n",
        "            for word in tokens:\n",
        "                if word not in stop_words:\n",
        "                    clean_tokens.append(word)\n",
        "\n",
        "            # remove contractions (eg. hasn't) and conjunctions (eg. on-campus)\n",
        "            # the following list comprehension removes a token if any character in\n",
        "            # the token is not an alphabet\n",
        "            if self.language == 'en':\n",
        "                proper_english_tokens = []\n",
        "                for word in clean_tokens:\n",
        "                    if word.isalpha():\n",
        "                        proper_english_tokens.append(word)\n",
        "\n",
        "                return proper_english_tokens\n",
        "\n",
        "            return clean_tokens\n",
        "        else:\n",
        "            raise Exception(\"No tokens found.\")\n",
        "\n",
        "    def vocab_size(self, text: Optional[str] = None) -> int:\n",
        "        '''The size of the vocabulary is the number of unique tokens in input\n",
        "        text.'''\n",
        "\n",
        "        # use a set to represent the vocabulary, as a set only stores unique\n",
        "        # elements\n",
        "        if not text:\n",
        "            if self.raw_text is not None:\n",
        "                vocabulary = set(self.__tokenize(self.raw_text))\n",
        "                return len(vocabulary)\n",
        "            else:\n",
        "                raise Exception(\"Couldn't read input file.\")\n",
        "        else:\n",
        "            if text:\n",
        "                vocabulary = set(self.__tokenize(text))\n",
        "                return len(vocabulary)\n",
        "            else:\n",
        "                raise Exception(\"Can't create vocabulary.\")\n",
        "\n",
        "    def word_freq(self, word: str, section: str) -> int:\n",
        "        '''Computes frequency of input word in given section of Brown corpus.'''\n",
        "\n",
        "        # find all the words in the given section\n",
        "        section_words = self.__remove_punctuations(\n",
        "            list(brown.words(categories=section)))\n",
        "\n",
        "        # find frequency of given word\n",
        "        freq = 0\n",
        "        for token in section_words:\n",
        "            if token == word:\n",
        "                freq += 1\n",
        "        return freq\n",
        "\n",
        "    def test_word_freq(self) -> None:\n",
        "        '''Test the word_freq method of the class by comparing with\n",
        "        nltk.FreqDist.'''\n",
        "\n",
        "        # choose 5 random categories of brown corpus\n",
        "        brown_categories = brown.categories()\n",
        "        test_categories = random.sample(brown_categories, 5)\n",
        "\n",
        "        print(\"-\" * 26)\n",
        "        print('{:>5} |{:>16}'.format(\"word_freq\", \"nltk.FreqDist\"))\n",
        "        print(\"-\" * 26)\n",
        "\n",
        "        # choose 3 random words from each of the 5 random categories chosen above\n",
        "        for category in test_categories:\n",
        "            section_words = self.__remove_punctuations(\n",
        "                list(brown.words(categories=category)))\n",
        "            test_words = random.sample(section_words, 3)\n",
        "            nltk_freq_dist = nltk.FreqDist(section_words)\n",
        "            for word in test_words:\n",
        "                    # verify the correctness using assert statement\n",
        "                assert self.word_freq(word, category) == nltk_freq_dist[word]\n",
        "\n",
        "                # print the values as well for visual comparison\n",
        "                print('{:>5}{:>15}'.format(self.word_freq(word, category),\n",
        "                                           nltk_freq_dist[word]))\n",
        "\n",
        "    def percent(self, word: str, text: Optional[str] = None) -> float:\n",
        "        '''Calculates how often a word occurs in a text as a percentage.'''\n",
        "\n",
        "        if not text:\n",
        "            if self.raw_text is not None:\n",
        "                # calculate total number of words\n",
        "                text_words = self.__remove_punctuations(\n",
        "                    self.__tokenize(self.raw_text))\n",
        "                total_count = len(text_words)\n",
        "\n",
        "                # calculate frequency of given word\n",
        "                frequency = 0\n",
        "                for token in text_words:\n",
        "                    if token == word:\n",
        "                        frequency += 1\n",
        "\n",
        "                # return percentage for word\n",
        "                return (frequency / total_count) * 100\n",
        "            else:\n",
        "                raise Exception(\"Couldn't read input file.\")\n",
        "        else:\n",
        "            if text:\n",
        "                # calculate total number of words\n",
        "                text_words = self.__remove_punctuations(self.__tokenize(text))\n",
        "                total_count = len(text_words)\n",
        "\n",
        "                # calculate frequency of given word\n",
        "                frequency = 0\n",
        "                for token in text_words:\n",
        "                    if token == word:\n",
        "                        frequency += 1\n",
        "\n",
        "                # return percentage for word\n",
        "                return (frequency / total_count) * 100\n",
        "            else:\n",
        "                raise Exception(\n",
        "                    \"Can't calculate frequency of word in input text.\")\n",
        "\n",
        "    def n_most_frequent(self, text: Optional[str] = None,\n",
        "                        num_words: Optional[int] = -1) -> List:\n",
        "        '''Finds N most frequent words of text, except stopwords, contractions,\n",
        "        conjunctions, punctuations.'''\n",
        "\n",
        "        # remove punctuations\n",
        "        if not text:\n",
        "            if self.raw_text is not None:\n",
        "                tokens = self.__remove_punctuations(\n",
        "                    self.__tokenize(self.raw_text))\n",
        "            else:\n",
        "                raise Exception(\"Couldn't read input file.\")\n",
        "        else:\n",
        "            if text:\n",
        "                tokens = self.__remove_punctuations(self.__tokenize(text))\n",
        "            else:\n",
        "                raise Exception(\"Can't tokenize input.\")\n",
        "\n",
        "        # remove stopwords, contractions, conjunctions\n",
        "        cleaned_tokens = self.__clean_tokens(tokens)\n",
        "\n",
        "        # calculate freq distribution of the tokens\n",
        "        freq_dist = nltk.FreqDist(cleaned_tokens)\n",
        "\n",
        "        # sort the frequency distribution in decreasing order of frequency\n",
        "        sorted_freq_dist = sorted(freq_dist.items(), key=lambda item: -item[1])\n",
        "\n",
        "        # if num_words is -1 (default), then return all word frequencies\n",
        "        most_freq_words = []\n",
        "        if num_words == -1:\n",
        "            for i in range(len(sorted_freq_dist)):\n",
        "                most_freq_words.append(sorted_freq_dist[i][0])\n",
        "        else:\n",
        "            for i in range(min(len(sorted_freq_dist), num_words)):\n",
        "                most_freq_words.append(sorted_freq_dist[i][0])\n",
        "\n",
        "        return most_freq_words\n",
        "\n",
        "    def n_letter_words(self, text: Optional[str] = None,\n",
        "                       num_words: Optional[int] = 4) -> List:\n",
        "        '''Finds all n letter words and prints them in decreasing order of\n",
        "        frequency.'''\n",
        "\n",
        "        # find reverse-sorted frequency of all words\n",
        "        if not text:\n",
        "            if self.raw_text is not None:\n",
        "                freq_sorted_words = self.n_most_frequent()\n",
        "            else:\n",
        "                raise Exception(\"Couldn't read input file.\")\n",
        "        else:\n",
        "            if text:\n",
        "                freq_sorted_words = self.n_most_frequent(text)\n",
        "            else:\n",
        "                raise Exception(\"Can't tokenize input.\")\n",
        "\n",
        "        # choose only n letter words from above output\n",
        "        n_letter_words = []\n",
        "        for word in freq_sorted_words:\n",
        "            if len(word) == num_words:\n",
        "                n_letter_words.append(word)\n",
        "\n",
        "        return n_letter_words\n",
        "\n",
        "    def words_occuring_n_times(self, count: Optional[int] = 3) -> List:\n",
        "        '''Finds all words that occur atleast n times in the Brown Corpus.'''\n",
        "\n",
        "        # all categories in brown corpus\n",
        "        brown_categories = brown.categories()\n",
        "\n",
        "        # aggregate all words from each category\n",
        "        all_words = []\n",
        "        for category in brown_categories:\n",
        "            section_words = self.__remove_punctuations(\n",
        "                list(brown.words(categories=category)))\n",
        "            all_words.extend(section_words)\n",
        "\n",
        "        # words from the list above, which have frequency >= count\n",
        "        valid_words = []\n",
        "        nltk_freq_dist = dict(nltk.FreqDist(all_words))\n",
        "        for word, freq in nltk_freq_dist.items():\n",
        "            if freq >= count:\n",
        "                valid_words.append(word)\n",
        "\n",
        "        return valid_words"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPDjDRjJ04G_"
      },
      "source": [
        "## English\n",
        "\n",
        "- For stopwords, I use the default stopwords collection from nltk for english.\n",
        "- The tasks mentioned in the assignment are executed consecutively in separate cells to show the output for each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uunEqJ-50iLb"
      },
      "source": [
        "english_solution = Basics(data_dir+data_file_1, 'en')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0Pj9WCO0n4V",
        "outputId": "a374a6e7-5676-4310-8708-a34d23a203c1"
      },
      "source": [
        "english_solution.add_line_numbers()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 \t ﻿Braving winter rain, thousands gathered at the Bhupen Hazarika memorial at Jalukbari here to join a protest rally against the Citizenship Amendment Act (CAA).\n",
            "2 \t Organised by the artistes of the state and backed by the All Assam Students’ Union (AASU), thousands of protesters, wearing black masks, hit the city streets to express their anger against the amended citizenship law and vowed to uproot the current government if it failed to respect public sentiment.\n",
            "3 \t The huge rally was organised a day after the BJP, in a show of strength, held a massive gathering of its workers in support of CAA at Khanapara ground.\n",
            "4 \t Leading Sunday’s rally from Jalukbari to Dighalipukhuri, a distance of around 14km, AASU general secretary Lurinjyoti Gogoi said, “The BJP showed its strength with its party workers but the anti-CAA movement has public support. In a democracy, public is the power and this movement has witnessed spontaneous public support from day one.”\n",
            "5 \t The AASU leader also warned the government against using power to suppress the movement. “The government has killed five people and many of their hired goons are attacking those who are opposing the Act. We warn the government not to apply force or power to dominate the movement,” he added.\n",
            "6 \t AASU chief adviser Samujjal Bhattacharjya said the movement would continue till the ultimate goal of securing the constitutional safeguards for the indigenous people of the state was achieved.\n",
            "7 \t Bhattacharjya said, “This movement will not stop till we achieve our final goal of securing the rights of the indigenous communities of the state.”\n",
            "8 \t Countering state BJP’s president Ranjeet Kumar Dass’s that “duck sellers, chicken sellers, vegetable vendors and egg sellers” were participating in the anti-CAA rallies, Assam Jatiyatabadi Yuva Chatra Parishad (AJYCP) general secretary Palash Changmai said, “Why can’t vegetable vendors or chicken sellers join the movement? If a tea seller can become the Prime Minister then I am sure a vegetable seller is also a patriot and can assert his democratic voice.”\n",
            "9 \t Singer Zubeen Garg who led the artiste community on Sunday, added, “The government is not listening to our voices and so we have worn these black masks in protest. If needed we are ready for a political alternative. We are ready to uproot this government if it continues to be blind and deaf to the people’s cry.”\n",
            "10 \t Amid the anti-CAA movement in the state, the demand for a political alternative to oust the ruling BJP in the next Assembly election is also growing.\n",
            "11 \t Popular singer Manas Robin said the artiste community would decide to take forward the protest against the amended citizenship law on January 17, when the state celebrates Shilpi Divas in memory of Assam’s cultural icon Jyoti Prasad Agarwala.\n",
            "12 \t He also called upon the various communities and organisations of the state to join hands in opposing CAA.\n",
            "13 \t Rain also failed to sdampen the spirit of the CAA protesters who gathered at Jeotimoral Sangha playground in Dibrugarh on Sunday.\n",
            "14 \t The protest was organised by Shilpi Samaj. The artiste fraternity protested through songs and poems.\n",
            "15 \t Addressing the gathering, Dibrugarh-based musician Prasanta Bordoloi said the CAA was against the people of Assam.\n",
            "16 \t “The ongoing anti-CAA movement reflects our rational and emotional sides. The CAA is against the secular fabric of the country and will divide the people of India. We, the artiste fraternity, assembled here to protest against it. The government has forcefully imposed it on Assam for vote bank politics,” Bordoloi said.\n",
            "17 \t The artistes expressed resentment by singing songs of Bhupen Hazarika.\n",
            "18 \t “Assam is not a dumping ground for illegal Bangladeshis. We do not accept the CAA in Assam because it violates the Assam Accord. We will continue our protest till CAA is scrapped,” said another protester.\n",
            "19 \t Additional reporting by Avik Chakraborty in Dibrugarh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9wJGIk80pmI",
        "outputId": "76120ce8-45ec-4cd0-b9d6-520d13534c00"
      },
      "source": [
        "print('Vocabulary size : ', english_solution.vocab_size())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size :  298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4zzvJqn0sHm",
        "outputId": "8ead9ce5-d94e-4bee-f8f5-4305641fad63"
      },
      "source": [
        "english_solution.test_word_freq()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------\n",
            "word_freq |   nltk.FreqDist\n",
            "--------------------------\n",
            "  806            806\n",
            "  263            263\n",
            "   44             44\n",
            "   36             36\n",
            "   61             61\n",
            "   95             95\n",
            "    3              3\n",
            "    6              6\n",
            "   85             85\n",
            "  127            127\n",
            "   16             16\n",
            "    2              2\n",
            "  530            530\n",
            "    1              1\n",
            "    2              2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWDzfld00tq5",
        "outputId": "45b5493e-3c74-4ae2-9c82-8804618f0bc7"
      },
      "source": [
        "word = 'we'\n",
        "print('Percentage of \\\"', word, '\\\" is : ', english_solution.percent(word), '%.')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of \" we \" is :  1.2326656394453006 %.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9S7O5Od0vSB",
        "outputId": "0101ab00-8b9d-46c8-e442-7ced07642650"
      },
      "source": [
        "print('10 most frequent words : ')\n",
        "print(english_solution.n_most_frequent(None, 10))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 most frequent words : \n",
            "['movement', 'caa', 'assam', 'said', 'government', 'protest', 'state', 'also', 'people', 'aasu']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkKPgy3e0wyj",
        "outputId": "427eb692-4321-49ae-9126-93e3e9f08c31"
      },
      "source": [
        "print('4 letter words in decreasing order of frequency from left to right: ')\n",
        "print(english_solution.n_letter_words())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 letter words in decreasing order of frequency from left to right: \n",
            "['said', 'also', 'aasu', 'join', 'till', 'rain', 'goal', 'city', 'huge', 'show', 'held', 'five', 'many', 'warn', 'stop', 'dass', 'duck', 'yuva', 'sure', 'garg', 'worn', 'deaf', 'amid', 'oust', 'next', 'take', 'icon', 'upon', 'vote', 'bank', 'avik']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3MXt1VT0yUe",
        "outputId": "a084ea0b-0942-4a7b-f1ab-060344857fd0"
      },
      "source": [
        "print('Words occuring thrice in Brown corpus : ')\n",
        "english_solution.words_occuring_n_times()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words occuring thrice in Brown corpus : \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dan',\n",
              " 'Morgan',\n",
              " 'told',\n",
              " 'himself',\n",
              " 'he',\n",
              " 'would',\n",
              " 'forget',\n",
              " 'Ann',\n",
              " 'Turner',\n",
              " 'He',\n",
              " 'was',\n",
              " 'well',\n",
              " 'rid',\n",
              " 'of',\n",
              " 'her',\n",
              " 'certainly',\n",
              " \"didn't\",\n",
              " 'want',\n",
              " 'a',\n",
              " 'wife',\n",
              " 'who',\n",
              " 'as',\n",
              " 'If',\n",
              " 'had',\n",
              " 'married',\n",
              " \"he'd\",\n",
              " 'have',\n",
              " 'been',\n",
              " 'asking',\n",
              " 'for',\n",
              " 'trouble',\n",
              " 'But',\n",
              " 'all',\n",
              " 'this',\n",
              " 'Sometimes',\n",
              " 'woke',\n",
              " 'up',\n",
              " 'in',\n",
              " 'the',\n",
              " 'middle',\n",
              " 'night',\n",
              " 'thinking',\n",
              " 'and',\n",
              " 'then',\n",
              " 'could',\n",
              " 'not',\n",
              " 'get',\n",
              " 'back',\n",
              " 'to',\n",
              " 'sleep',\n",
              " 'His',\n",
              " 'plans',\n",
              " 'dreams',\n",
              " 'revolved',\n",
              " 'around',\n",
              " 'so',\n",
              " 'much',\n",
              " 'long',\n",
              " 'that',\n",
              " 'now',\n",
              " 'felt',\n",
              " 'if',\n",
              " 'nothing',\n",
              " 'The',\n",
              " 'easiest',\n",
              " 'thing',\n",
              " 'be',\n",
              " 'sell',\n",
              " 'out',\n",
              " 'Al',\n",
              " 'Budd',\n",
              " 'leave',\n",
              " 'country',\n",
              " 'but',\n",
              " 'there',\n",
              " 'stubborn',\n",
              " 'streak',\n",
              " 'him',\n",
              " \"wouldn't\",\n",
              " 'allow',\n",
              " 'it',\n",
              " 'best',\n",
              " 'bitterness',\n",
              " 'disappointment',\n",
              " 'poisoned',\n",
              " 'hard',\n",
              " 'work',\n",
              " 'found',\n",
              " 'tired',\n",
              " 'enough',\n",
              " 'at',\n",
              " 'went',\n",
              " 'simply',\n",
              " 'because',\n",
              " 'too',\n",
              " 'exhausted',\n",
              " 'stay',\n",
              " 'awake',\n",
              " 'Each',\n",
              " 'day',\n",
              " 'less',\n",
              " 'often',\n",
              " 'each',\n",
              " 'hurt',\n",
              " 'little',\n",
              " 'poignant',\n",
              " 'plenty',\n",
              " 'do',\n",
              " 'Because',\n",
              " 'summer',\n",
              " 'unusually',\n",
              " 'dry',\n",
              " 'hot',\n",
              " 'spring',\n",
              " 'produced',\n",
              " 'smaller',\n",
              " 'stream',\n",
              " 'than',\n",
              " 'ordinary',\n",
              " 'years',\n",
              " 'grass',\n",
              " 'meadows',\n",
              " 'came',\n",
              " 'fast',\n",
              " 'warm',\n",
              " 'weather',\n",
              " 'here',\n",
              " 'afford',\n",
              " 'lose',\n",
              " 'drop',\n",
              " 'precious',\n",
              " 'water',\n",
              " 'spent',\n",
              " 'most',\n",
              " 'his',\n",
              " 'waking',\n",
              " 'hours',\n",
              " 'along',\n",
              " 'no',\n",
              " 'idea',\n",
              " 'how',\n",
              " 'time',\n",
              " 'give',\n",
              " 'In',\n",
              " 'any',\n",
              " 'case',\n",
              " 'intention',\n",
              " 'being',\n",
              " 'caught',\n",
              " 'asleep',\n",
              " 'carried',\n",
              " 'revolver',\n",
              " 'its',\n",
              " 'holster',\n",
              " 'on',\n",
              " 'hip',\n",
              " 'took',\n",
              " 'Winchester',\n",
              " 'with',\n",
              " 'leaned',\n",
              " 'against',\n",
              " 'fence',\n",
              " 'stopped',\n",
              " 'every',\n",
              " 'few',\n",
              " 'minutes',\n",
              " 'shovel',\n",
              " 'studied',\n",
              " 'horizon',\n",
              " 'happened',\n",
              " 'dragging',\n",
              " 'monotonous',\n",
              " 'calm',\n",
              " 'When',\n",
              " 'late',\n",
              " 'afternoon',\n",
              " 'last',\n",
              " 'June',\n",
              " 'saw',\n",
              " 'two',\n",
              " 'people',\n",
              " 'top',\n",
              " 'ridge',\n",
              " 'south',\n",
              " 'walk',\n",
              " 'toward',\n",
              " 'house',\n",
              " 'quit',\n",
              " 'immediately',\n",
              " 'strode',\n",
              " 'rifle',\n",
              " 'It',\n",
              " 'some',\n",
              " 'kind',\n",
              " 'trick',\n",
              " 'thought',\n",
              " 'No',\n",
              " 'one',\n",
              " 'walked',\n",
              " 'least',\n",
              " 'Ed',\n",
              " 'Dow',\n",
              " 'or',\n",
              " 'Dutch',\n",
              " 'rest',\n",
              " 'Bar',\n",
              " 'B',\n",
              " 'crew',\n",
              " 'watched',\n",
              " 'figures',\n",
              " 'puzzled',\n",
              " 'they',\n",
              " 'were',\n",
              " 'closer',\n",
              " 'woman',\n",
              " 'more',\n",
              " 'ever',\n",
              " 'cleaned',\n",
              " 'left',\n",
              " 'picked',\n",
              " 'started',\n",
              " 'downstream',\n",
              " 'visitors',\n",
              " 'crawled',\n",
              " 'through',\n",
              " 'crossing',\n",
              " 'meadow',\n",
              " 'Now',\n",
              " 'both',\n",
              " 'man',\n",
              " 'moving',\n",
              " 'slowly',\n",
              " 'irregularly',\n",
              " 'staggering',\n",
              " 'struggle',\n",
              " 'remain',\n",
              " 'their',\n",
              " 'feet',\n",
              " 'Reaching',\n",
              " 'ahead',\n",
              " 'them',\n",
              " 'waited',\n",
              " 'hands',\n",
              " 'They',\n",
              " 'north',\n",
              " 'young',\n",
              " 'nineteen',\n",
              " 'twenty',\n",
              " 'dirty',\n",
              " 'clothes',\n",
              " 'torn',\n",
              " 'girl',\n",
              " 'she',\n",
              " 'fell',\n",
              " 'when',\n",
              " 'still',\n",
              " 'from',\n",
              " 'front',\n",
              " 'door',\n",
              " 'She',\n",
              " 'lay',\n",
              " 'making',\n",
              " 'effort',\n",
              " 'boy',\n",
              " 'porch',\n",
              " 'sat',\n",
              " 'down',\n",
              " 'gaze',\n",
              " 'half',\n",
              " 'expecting',\n",
              " 'shoot',\n",
              " 'really',\n",
              " 'caring',\n",
              " 'hesitated',\n",
              " 'good',\n",
              " 'think',\n",
              " 'possible',\n",
              " 'couple',\n",
              " 'pretending',\n",
              " 'licked',\n",
              " 'lips',\n",
              " 'asked',\n",
              " 'Could',\n",
              " 'we',\n",
              " 'drink',\n",
              " 'jerked',\n",
              " 'head',\n",
              " 'kitchen',\n",
              " 'said',\n",
              " 'Leaning',\n",
              " 'Get',\n",
              " \"There's\",\n",
              " 'move',\n",
              " 'say',\n",
              " 'anything',\n",
              " 'Her',\n",
              " 'eyes',\n",
              " 'glazed',\n",
              " 'hear',\n",
              " 'even',\n",
              " 'see',\n",
              " 'reached',\n",
              " 'point',\n",
              " 'which',\n",
              " 'care',\n",
              " 'looked',\n",
              " 'face',\n",
              " 'very',\n",
              " 'thin',\n",
              " 'burned',\n",
              " 'by',\n",
              " 'sun',\n",
              " 'until',\n",
              " 'skin',\n",
              " 'dead',\n",
              " 'peeling',\n",
              " 'new',\n",
              " 'under',\n",
              " 'red',\n",
              " 'angry',\n",
              " 'blond',\n",
              " 'hair',\n",
              " 'dress',\n",
              " 'several',\n",
              " 'places',\n",
              " 'shoes',\n",
              " 'completely',\n",
              " 'worn',\n",
              " 'practically',\n",
              " 'protection',\n",
              " 'must',\n",
              " 'sole',\n",
              " 'off',\n",
              " 'foot',\n",
              " 'bruised',\n",
              " 'bleeding',\n",
              " 'sliding',\n",
              " 'hand',\n",
              " 'shoulders',\n",
              " 'other',\n",
              " 'knees',\n",
              " 'into',\n",
              " 'amazingly',\n",
              " 'light',\n",
              " 'relaxed',\n",
              " 'arms',\n",
              " \"wasn't\",\n",
              " 'sure',\n",
              " 'conscious',\n",
              " 'Any',\n",
              " 'lingering',\n",
              " 'suspicion',\n",
              " 'dispelled',\n",
              " 'go',\n",
              " 'far',\n",
              " 'fool',\n",
              " 'kill',\n",
              " 'Besides',\n",
              " 'sweet',\n",
              " 'attracted',\n",
              " 'put',\n",
              " 'couch',\n",
              " 'going',\n",
              " 'dropped',\n",
              " 'chair',\n",
              " 'beside',\n",
              " 'table',\n",
              " 'deal',\n",
              " 'alike',\n",
              " 'Both',\n",
              " 'blonde',\n",
              " 'blue',\n",
              " 'faint',\n",
              " 'similarity',\n",
              " 'features',\n",
              " 'filled',\n",
              " 'dipper',\n",
              " 'bucket',\n",
              " 'shelf',\n",
              " 'room',\n",
              " 'lifted',\n",
              " \"girl's\",\n",
              " 'held',\n",
              " 'edge',\n",
              " 'mouth',\n",
              " 'drank',\n",
              " 'murmured',\n",
              " 'Thank',\n",
              " 'you',\n",
              " 'lowered',\n",
              " 'stood',\n",
              " 'looking',\n",
              " 'moment',\n",
              " 'wondering',\n",
              " 'what',\n",
              " 'reduced',\n",
              " 'condition',\n",
              " 'seen',\n",
              " 'wagons',\n",
              " 'families',\n",
              " 'almost',\n",
              " 'starving',\n",
              " 'death',\n",
              " 'never',\n",
              " 'bad',\n",
              " 'these',\n",
              " 'returned',\n",
              " 'built',\n",
              " 'fire',\n",
              " 'buckets',\n",
              " 'poured',\n",
              " 'copper',\n",
              " 'placed',\n",
              " 'stove',\n",
              " 'brought',\n",
              " 'faced',\n",
              " 'Who',\n",
              " 'are',\n",
              " \"I'm\",\n",
              " 'Billy',\n",
              " 'Jones',\n",
              " 'answered',\n",
              " \"That's\",\n",
              " 'my',\n",
              " 'Sharon',\n",
              " 'We',\n",
              " 'ran',\n",
              " 'money',\n",
              " \"haven't\",\n",
              " 'eaten',\n",
              " 'days',\n",
              " 'What',\n",
              " 'doing',\n",
              " 'Are',\n",
              " 'Wyoming',\n",
              " 'nodded',\n",
              " 'About',\n",
              " 'five',\n",
              " 'miles',\n",
              " 'line',\n",
              " 'sighed',\n",
              " 'relieved',\n",
              " \"We've\",\n",
              " 'ranchers',\n",
              " 'turned',\n",
              " 'us',\n",
              " 'You',\n",
              " 'mean',\n",
              " 'dragged',\n",
              " 'your',\n",
              " 'over',\n",
              " 'demanded',\n",
              " 'town',\n",
              " 'only',\n",
              " 'about',\n",
              " 'six',\n",
              " 'Why',\n",
              " 'This',\n",
              " 'is',\n",
              " 'mighty',\n",
              " 'empty',\n",
              " 'ranch',\n",
              " 'three',\n",
              " \"You'd\",\n",
              " 'starved',\n",
              " \"you'd\",\n",
              " 'missed',\n",
              " 'Then',\n",
              " \"we're\",\n",
              " 'lucky',\n",
              " 'got',\n",
              " 'job',\n",
              " 'Mr.',\n",
              " 'silent',\n",
              " 'use',\n",
              " 'year',\n",
              " 'cook',\n",
              " 'knew',\n",
              " 'might',\n",
              " 'dismissed',\n",
              " 'possibility',\n",
              " 'once',\n",
              " 'haunted',\n",
              " 'killer',\n",
              " \"hadn't\",\n",
              " 'shaved',\n",
              " 'weeks',\n",
              " 'sparse',\n",
              " 'beard',\n",
              " 'giving',\n",
              " 'pathetic',\n",
              " 'expression',\n",
              " 'There',\n",
              " 'running',\n",
              " 'something',\n",
              " \"He'd\",\n",
              " 'an',\n",
              " 'let',\n",
              " \"couldn't\",\n",
              " 'send',\n",
              " 'either',\n",
              " 'I',\n",
              " 'help',\n",
              " 'finally',\n",
              " \"can't\",\n",
              " 'pay',\n",
              " 'guess',\n",
              " 'better',\n",
              " 'morning',\n",
              " \"We'll\",\n",
              " 'our',\n",
              " 'keep',\n",
              " 'eagerly',\n",
              " \"I've\",\n",
              " 'mine',\n",
              " 'San',\n",
              " 'Juan',\n",
              " 'used',\n",
              " \"she's\",\n",
              " 'cooked',\n",
              " 'restaurant',\n",
              " \"I'll\",\n",
              " 'Right',\n",
              " 'need',\n",
              " 'meal',\n",
              " 'bath',\n",
              " 'Your',\n",
              " \"wife's\",\n",
              " 'terrible',\n",
              " 'shape',\n",
              " 'know',\n",
              " 'box',\n",
              " 'wood',\n",
              " 'again',\n",
              " 'supper',\n",
              " 'set',\n",
              " 'ready',\n",
              " 'wash',\n",
              " 'rubbed',\n",
              " 'stretched',\n",
              " 'mess',\n",
              " 'suddenly',\n",
              " 'alarmed',\n",
              " 'How',\n",
              " 'did',\n",
              " 'Aj',\n",
              " 'gave',\n",
              " 'Oh',\n",
              " 'stared',\n",
              " 'wide',\n",
              " \"You're\",\n",
              " 'Do',\n",
              " 'take',\n",
              " 'strays',\n",
              " 'come',\n",
              " \"don't\",\n",
              " 'many',\n",
              " 'coming',\n",
              " 'Think',\n",
              " 'can',\n",
              " 'Of',\n",
              " 'course',\n",
              " 'staggered',\n",
              " 'arm',\n",
              " 'helped',\n",
              " 'shaking',\n",
              " 'sorry',\n",
              " 'usually',\n",
              " 'strong',\n",
              " 'awfully',\n",
              " 'And',\n",
              " 'hungry',\n",
              " 'Start',\n",
              " \"It's\",\n",
              " \"it's\",\n",
              " 'eat',\n",
              " 'Not',\n",
              " 'cried',\n",
              " 'food',\n",
              " 'satisfied',\n",
              " \"he's\",\n",
              " 'grateful',\n",
              " 'way',\n",
              " 'made',\n",
              " 'ashamed',\n",
              " 'Lord',\n",
              " 'looks',\n",
              " 'fools',\n",
              " 'drunkards',\n",
              " 'laughed',\n",
              " 'Which',\n",
              " \"We're\",\n",
              " 'dishes',\n",
              " 'before',\n",
              " 'dark',\n",
              " 'tub',\n",
              " 'where',\n",
              " 'hung',\n",
              " 'nail',\n",
              " 'wall',\n",
              " \"You'll\",\n",
              " 'feel',\n",
              " 'lot',\n",
              " 'after',\n",
              " 'Mrs.',\n",
              " \"she'll\",\n",
              " 'right',\n",
              " 'quickly',\n",
              " 'expect',\n",
              " 'just',\n",
              " 'find',\n",
              " 'me',\n",
              " 'needle',\n",
              " 'thread',\n",
              " 'My',\n",
              " 'needs',\n",
              " 'bedroom',\n",
              " 'bed',\n",
              " 'spare',\n",
              " \"isn't\",\n",
              " \"you'll\",\n",
              " 'blankets',\n",
              " 'Some',\n",
              " 'early',\n",
              " 'followed',\n",
              " 'closing',\n",
              " 'behind',\n",
              " 'slept',\n",
              " 'together',\n",
              " 'since',\n",
              " 'chances',\n",
              " 'getting',\n",
              " 'pregnant',\n",
              " 'sleeping',\n",
              " 'embarrassed',\n",
              " 'understand',\n",
              " 'why',\n",
              " 'jobs',\n",
              " 'first',\n",
              " 'place',\n",
              " 'fired',\n",
              " 'pair',\n",
              " 'lost',\n",
              " 'whipped',\n",
              " 'kids',\n",
              " 'Gavin',\n",
              " 'paused',\n",
              " 'wearily',\n",
              " \"they'd\",\n",
              " 'dawn',\n",
              " 'make',\n",
              " 'sank',\n",
              " 'began',\n",
              " 'rock',\n",
              " 'life',\n",
              " 'guilt',\n",
              " 'Beneath',\n",
              " 'black',\n",
              " 'shirt',\n",
              " 'frail',\n",
              " 'shook',\n",
              " 'pain',\n",
              " 'broke',\n",
              " 'throat',\n",
              " 'stored',\n",
              " 'shattering',\n",
              " 'free',\n",
              " 'slow',\n",
              " 'gasps',\n",
              " 'Clayton',\n",
              " 'tried',\n",
              " 'call',\n",
              " 'known',\n",
              " 'Against',\n",
              " 'rally',\n",
              " 'anger',\n",
              " 'bent',\n",
              " 'powerless',\n",
              " \"Gavin's\",\n",
              " 'moved',\n",
              " 'stoop',\n",
              " 'catch',\n",
              " 'words',\n",
              " 'remember',\n",
              " 'Big',\n",
              " 'Charlie',\n",
              " 'whispered',\n",
              " 'stuck',\n",
              " 'Just',\n",
              " 'half-breed',\n",
              " 'meant',\n",
              " 'fight',\n",
              " 'Tom',\n",
              " 'English',\n",
              " \"brother's\",\n",
              " 'son',\n",
              " 'fair',\n",
              " 'provoked',\n",
              " 'believed',\n",
              " 'killed',\n",
              " 'dumped',\n",
              " 'body',\n",
              " 'rose',\n",
              " 'garden',\n",
              " 'nights',\n",
              " 'ago',\n",
              " 'men',\n",
              " 'cleared',\n",
              " 'Clay',\n",
              " 'treated',\n",
              " 'wiped',\n",
              " 'sleeve',\n",
              " 'childish',\n",
              " 'wonder',\n",
              " 'shyly',\n",
              " 'wherever',\n",
              " \"you're\",\n",
              " 'goin',\n",
              " 'Yes',\n",
              " 'hate',\n",
              " 'choked',\n",
              " 'murmuring',\n",
              " 'Come',\n",
              " 'old',\n",
              " 'beckoned',\n",
              " 'finger',\n",
              " 'forward',\n",
              " 'slipped',\n",
              " 'chest',\n",
              " 'fiercely',\n",
              " 'All',\n",
              " 'away',\n",
              " 'wanted',\n",
              " 'part',\n",
              " \"there's\",\n",
              " 'nothin',\n",
              " 'gone',\n",
              " 'God',\n",
              " 'Heaven',\n",
              " 'refuse',\n",
              " 'That',\n",
              " 'mock',\n",
              " \"Can't\",\n",
              " 'closed',\n",
              " 'tears',\n",
              " 'freed',\n",
              " 'embrace',\n",
              " 'stepped',\n",
              " 'fearfully',\n",
              " 'horses',\n",
              " 'saddle',\n",
              " 'bring',\n",
              " 'round',\n",
              " 'burst',\n",
              " 'confinement',\n",
              " 'cold',\n",
              " 'air',\n",
              " 'stallion',\n",
              " 'barn',\n",
              " 'tightened',\n",
              " 'blanket',\n",
              " 'working',\n",
              " 'touch',\n",
              " 'darkness',\n",
              " 'comforting',\n",
              " 'animal',\n",
              " 'easy',\n",
              " 'finished',\n",
              " 'led',\n",
              " 'mare',\n",
              " 'smelled',\n",
              " 'heat',\n",
              " 'paw',\n",
              " 'turf',\n",
              " 'reins',\n",
              " 'knot',\n",
              " 'veranda',\n",
              " 'post',\n",
              " 'patted',\n",
              " 'flesh',\n",
              " 'neck',\n",
              " 'backed',\n",
              " \"doesn't\",\n",
              " 'will',\n",
              " 'figure',\n",
              " 'taken',\n",
              " 'carbine',\n",
              " 'trailed',\n",
              " 'stock',\n",
              " 'floor',\n",
              " 'called',\n",
              " 'steps',\n",
              " 'To',\n",
              " 'valley',\n",
              " 'someone',\n",
              " 'may',\n",
              " 'California',\n",
              " 'yet',\n",
              " 'crazy',\n",
              " 'nod',\n",
              " 'land',\n",
              " 'A',\n",
              " 'mark',\n",
              " 'Two',\n",
              " 'like',\n",
              " 'fine',\n",
              " 'maybe',\n",
              " \"one's\",\n",
              " 'fresh',\n",
              " 'father',\n",
              " 'stand',\n",
              " 'approached',\n",
              " 'horse',\n",
              " 'laid',\n",
              " 'quivering',\n",
              " 'Help',\n",
              " 'stiff',\n",
              " 'gently',\n",
              " 'child',\n",
              " \"They'll\",\n",
              " 'trample',\n",
              " 'loved',\n",
              " 'grow',\n",
              " 'alone',\n",
              " 'river',\n",
              " 'nice',\n",
              " 'peaceful',\n",
              " 'quiet',\n",
              " 'swung',\n",
              " 'yard',\n",
              " 'circle',\n",
              " 'cast',\n",
              " 'lamp',\n",
              " 'burning',\n",
              " 'Thirty-five',\n",
              " 'rode',\n",
              " 'measured',\n",
              " 'pace',\n",
              " 'Dawn',\n",
              " 'soon',\n",
              " 'coldest',\n",
              " 'moon',\n",
              " 'sunk',\n",
              " 'below',\n",
              " 'crest',\n",
              " 'mountains',\n",
              " 'grown',\n",
              " 'accustomed',\n",
              " 'absence',\n",
              " 'primeval',\n",
              " 'trespassed',\n",
              " 'those',\n",
              " 'rustle',\n",
              " 'blade',\n",
              " 'wind',\n",
              " 'savage',\n",
              " 'brooding',\n",
              " 'broken',\n",
              " 'bitterly',\n",
              " 'inert',\n",
              " 'landscape',\n",
              " 'caravan',\n",
              " 'desires',\n",
              " 'passed',\n",
              " 'mind',\n",
              " 'strewn',\n",
              " 'dying',\n",
              " 'vain',\n",
              " 'groped',\n",
              " 'reassemble',\n",
              " 'bones',\n",
              " 'relationships',\n",
              " 'sought',\n",
              " 'desperately',\n",
              " 'silence',\n",
              " 'oppressed',\n",
              " 'bend',\n",
              " 'low',\n",
              " \"horse's\",\n",
              " 'hide',\n",
              " 'begun',\n",
              " 'blow',\n",
              " 'twisting',\n",
              " 'search',\n",
              " 'framed',\n",
              " 'gray',\n",
              " 'hills',\n",
              " 'dissolve',\n",
              " 'bold',\n",
              " 'loose',\n",
              " 'high',\n",
              " 'feathers',\n",
              " 'swept',\n",
              " 'stars',\n",
              " 'sky',\n",
              " 'spread',\n",
              " 'ground',\n",
              " 'revealed',\n",
              " 'glimmer',\n",
              " 'contours',\n",
              " 'trees',\n",
              " 'fences',\n",
              " 'shadowed',\n",
              " 'weary',\n",
              " 'though',\n",
              " 'posted',\n",
              " 'hundred',\n",
              " 'yards',\n",
              " 'shelter',\n",
              " 'flung',\n",
              " 'themselves',\n",
              " 'saloon',\n",
              " 'crying',\n",
              " 'intelligence',\n",
              " \"night's\",\n",
              " 'drinking',\n",
              " 'faces',\n",
              " 'baggy',\n",
              " 'liquor',\n",
              " 'flushed',\n",
              " 'courage',\n",
              " 'greeted',\n",
              " 'news',\n",
              " 'angrily',\n",
              " 'cheated',\n",
              " 'purpose',\n",
              " 'Lester',\n",
              " 'heard',\n",
              " 'muttering',\n",
              " 'reveal',\n",
              " 'desire',\n",
              " 'worked',\n",
              " 'tongue',\n",
              " 'hollow',\n",
              " 'cheek',\n",
              " 'voice',\n",
              " 'cracked',\n",
              " \"He's\",\n",
              " 'Keep',\n",
              " 'Purvis',\n",
              " 'snarled',\n",
              " 'brother',\n",
              " 'lied',\n",
              " 'Joe',\n",
              " 'First',\n",
              " 'ridden',\n",
              " 'cattle',\n",
              " 'end',\n",
              " 'remembered',\n",
              " 'smirk',\n",
              " 'own',\n",
              " 'cringing',\n",
              " 'feeling',\n",
              " \"Clayton's\",\n",
              " 'fallen',\n",
              " 'Gap',\n",
              " 'Nellie',\n",
              " 'love',\n",
              " 'Roy',\n",
              " 'dance',\n",
              " 'party',\n",
              " 'treats',\n",
              " 'dirt',\n",
              " 'mocking',\n",
              " 'smile',\n",
              " 'poker',\n",
              " 'game',\n",
              " 'thinkin',\n",
              " 'halfway',\n",
              " \"won't\",\n",
              " \"they'll\",\n",
              " 'ride',\n",
              " \"that's\",\n",
              " 'shoulder',\n",
              " 'drunk',\n",
              " 'wild',\n",
              " 'break',\n",
              " 'cloying',\n",
              " 'warmth',\n",
              " 'fled',\n",
              " 'grunted',\n",
              " 'pushing',\n",
              " 'side',\n",
              " 'jacket',\n",
              " 'raised',\n",
              " 'shut',\n",
              " 'mounted',\n",
              " 'others',\n",
              " 'safe',\n",
              " 'distance',\n",
              " 'mist',\n",
              " 'swirled',\n",
              " 'sudden',\n",
              " 'clear',\n",
              " 'clouds',\n",
              " 'parted',\n",
              " 'sunlight',\n",
              " 'swooped',\n",
              " 'stain',\n",
              " 'earth',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HQCbyzm06J2"
      },
      "source": [
        "## Bengali\n",
        "\n",
        "- Bengali is written using unicode.\n",
        "- I use language specific stopwords for Bengali from [this](https://github.com/stopwords-iso/stopwords-bn/blob/master/stopwords-bn.txt) source.\n",
        "- The tasks mentioned in the assignment are executed consecutively in separate cells to show the output for each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbUIv76I096u"
      },
      "source": [
        "stopwords_bn = set(open(data_dir+bengali_stopwords).read().split())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61BfdtDD1Bhm"
      },
      "source": [
        "bengali_solution = Basics(data_dir+data_file_2, 'bn', stopwords_bn)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjJ-VTzk1ENs",
        "outputId": "5932467e-3dc1-42f5-c3aa-ff9c21710bce"
      },
      "source": [
        "bengali_solution.add_line_numbers()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 \t ﻿এক টাকা বাড়লেই রাজস্থানে সেঞ্চুরি হাঁকাবে পেট্রোলের দাম। ডিজেলের দামও ৯০-এর কোটা পার করেছে সেখানে। যা দামের নিরিখে দেশের মধ্যে সবচেয়ে বেশি।\n",
            "2 \t দাম বৃদ্ধির কারণ হিসেবে বিশ্ব বাজারে অশোধিত তেল এবং দুই জ্বালানির দরের হিসেবকে দায়ী করেছে কেন্দ্র। তবে বিরোধীদের অভিযোগ, পেট্রোল এবং ডিজেলের উপর কেন্দ্রের শুল্ক বৃদ্ধির কারণেই ক্রেতাদের বাড়তি কড়ি গুনতে হচ্ছে। কংগ্রেস সাংসদ অধীররঞ্জন চৌধুরী তেলের দাম বৃদ্ধি নিয়ে কেন্দ্রকে কটাক্ষ করে টুইট করেন, ‘আত্মনির্ভর ভারত বৃদ্ধির আরও একটা শিখরে পৌঁছতে চলেছে। সেঞ্চুরি থেকে পাঁচ পয়েন্ট দূরে রয়েছে পেট্রোলের দাম। খুব শীঘ্রই নরেন্দ্র মোদীজি পেট্রোলের দাম ১০০ টাকা করবেন।’\n",
            "3 \t রবিবার গোটা দেশে লিটারপিছু ২৯ পয়সা বেড়েছে পেট্রোলের দাম। লিটারপিছু ডিজেলের দাম বেড়েছে ৩২ পয়সা। পর পর টানা ৬ দিন বাড়ল এই জীবাশ্ম জ্বালানির দাম। এ ক’দিনে লিটারপিছু পেট্রোলের মোট দাম বেড়েছে ১.৮০ টাকা এবং ডিজেলের ১.৮৮ টাকা।\n",
            "4 \t দাম বৃদ্ধির নিরিখে রাজস্থানের পরেই রয়েছে মুম্বই। সেখানে পেট্রোলের দাম ৯৫ টাকা ছাড়িয়ে গিয়েছে। ডিজেল ৮৬.০৪ টাকা। দেশের চার মেট্রো শহরের মধ্যে মুম্বইতেই এই দুই জ্বালানির দাম সবচেয়ে বেশি। দিল্লিতে পেট্রোল ও ডিজেলের দাম যথাক্রমে দাম ৮৮.৭৩ এবং ৭৯.০৬ টাকা। চেন্নাইয়েও পেট্রোল ৯০-এর গন্ডি টপকেছে। একই ছবি কলকাতারও। এখানে লিটারপিছু পেট্রোলের দাম ৯০.০১ টাকা। ডিজেল ৮২.৬৫ টাকা।\n",
            "5 \t দীর্ঘ এক মাস দামের কোনও হেরফের না হওয়ার পর গত ৬ জানুয়ারি থেকে প্রতি দিনই একটু একুট তেলের দাম বাড়তে শুরু করে। এ ভাবে বাড়তে থাকলে খুব শীঘ্রই মেট্রো শহরগুলোতেও পেট্রোল এবং ডিজেলের দাম সেঞ্চুরি হাঁকাবে।\n",
            "6 \t দেশের মেট্রো শহরগুলিতে পেট্রল-ডিজেলের দাম ফের ঊর্ধ্বমুখী। এই নিয়ে টানা চার দিন কলকাতা-সহ ওই শহরগুলিতে জ্বালানীর দাম বাড়ল। শুক্রবার এর দাম এখনও পর্যন্ত সবচেয়ে বেশি হয়েছে।\n",
            "7 \t শুক্রবার দেশের তেল বিক্রয়কারী সংস্থাগুলি জ্বালানীর দাম প্রতি লিটারে প্রায় ৩০ পয়সা করে বাড়িয়েছে। ফলে শুক্রবার সকাল থেকে কলকাতায় পেট্রলের দাম লিটার প্রতি ৮৯.৪৪ টাকা। অন্য দিকে, ডিজেলের দাম বেড়ে হয়েছে প্রতি লিটারে ৮১.৯৬ টাকা। দিল্লিতে ২৯ পয়সা বেড়ে ১ লিটার পেট্রলের দাম দাঁড়িয়েছে ৮৮.১৪ টাকা। রাজধানীতে ডিজেলের দাম বেড়েছে ৩৫ পয়সা। শুক্রবার তা বিক্রি হচ্ছে লিটার প্রতি ৭৮.৩৮ টাকায়। মুম্বইতে ১ লিটার পেট্রলের দাম হয়েছে ৯৪.৬৪ টাকা এবং ওই একই পরিমাণ ডিজেল কিনতে খরচ করতে হচ্ছে ৮৫.৩২ টাকা। এই তিন শহরের পাশাপাশি দেশের অন্য মেট্রো শহর চেন্নাইতে প্রতি লিটার পেট্রল এবং ডিজেলের দাম যথাক্রমে ৯০.৪৪ ও ৮৩.৫২ টাকা।\n",
            "8 \t দেশের সবচেয়ে বড় তেল বিক্রয়কারী সংস্থা ইন্ডিয়ান অয়েল কর্পোরেশন জানিয়েছে, চলতি বছরের ৬ জানুয়ারি থেকে এ দেশে তেলের দাম ঊর্ধ্বমুখী হতে শুরু করেছে। তার আগে মাসখানেক তেলের দরে কোনও হেরফের হয়নি। বিশ্ব জুড়ে অপরিশোধিত তেলের দাম বাড়ার জন্য এ দেশের জ্বালানীর দাম বেড়েছে। পাশাপাশি, বিদেশি মুদ্রা বিনিময়মূল্যে ওঠানামার উপর নির্ভর করে তেলের দাম।\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE-5Ia061F0b",
        "outputId": "ef637501-e943-4751-c472-b82eee4c58c0"
      },
      "source": [
        "print('Vocabulary size : ', bengali_solution.vocab_size())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size :  234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvt4rEqH1K3X",
        "outputId": "24534970-df7f-4b34-988f-8bea43c53264"
      },
      "source": [
        "word = 'টাকা'\n",
        "print('Percentage of \\\"', word, '\\\" is : ', bengali_solution.percent(word), '%.')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of \" টাকা \" is :  1.2345679012345678 %.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SV1u1zI1Lc2",
        "outputId": "e743b34c-c885-428e-c352-c15acb980939"
      },
      "source": [
        "print('10 most frequent words : ')\n",
        "print(bengali_solution.n_most_frequent(None, 10))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 most frequent words : \n",
            "['দাম', 'টাকা।', 'ডিজেলের', 'পেট্রোলের', 'দেশের', 'তেলের', 'টাকা', 'দাম।', 'লিটার', 'সবচেয়ে']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBVHIcO_1O9b",
        "outputId": "b293c4c2-5c82-4320-e6d0-8f8cac9692cf"
      },
      "source": [
        "print('4 letter words in decreasing order of frequency from left to right: ')\n",
        "print(bengali_solution.n_letter_words())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 letter words in decreasing order of frequency from left to right: \n",
            "['টাকা', 'দাম।', 'পয়সা', 'দেশে', 'টানা', 'দামও', 'কোটা', 'দরের', 'দায়ী', 'কড়ি', 'টুইট', 'ভারত', 'একটা', 'পাঁচ', 'দূরে', 'দিনে', '১.৮০', '১.৮৮', 'দিনই', 'একটু', 'একুট', 'করে।', 'সকাল', 'অয়েল', 'চলতি']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}